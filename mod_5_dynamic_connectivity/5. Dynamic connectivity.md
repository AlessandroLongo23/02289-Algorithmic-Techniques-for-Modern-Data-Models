## Problem definition
Obtain an efficient data structure supporting the following operations in a dynamically changing graph $G=(V,E)$.
- $\text{insert}(u,v)$: inserts edge $(u,v)$ in $E$
- $\text{delete}(u,v)$: deletes edge $(u,v)$ in $E$
- $\text{connected}(u,v)$: reports whether vertices $u$ and $v$ are connected in $G$

We refer to $\text{insert}$ and $\text{delete}$ as update operations and to $\text{connected}$ as a query operations.
Initial graph has $|V|=n$ vertices, and $E=\emptyset$.
Updates and queries are revealed one by one in an online sequence. We give a data structure with:
- $O(\log(n))$ worst-case query time
- $O(\log^2(n))$ amortized update time

### Edge levels and clusters
Our data structure will maintain a level $l(e)$ for each $e\in E$ where:
$$0\le l(e)\le l_\max=\lfloor\log_n\rfloor$$
For $0\le i\le l_\max$, let $G_i=(V,E_i)$ denote the subgraph of $G$ containing edges $e$ with $l(e)\ge i$.
We have $E=E_0\supseteq E_1\supseteq E_2\supseteq\ldots\supseteq E_{l_max}$
Connected components of $G_i$ are called $i$-clusters or just clusters.
An invariant is that any $i$-cluster contains at most $\left\lfloor\dfrac n{2^i}\right\rfloor$ vertices.
$0$-clusters are the connected components of $G$.
$l_\max$-clusters are vertices of $V$.
![[]]
### Cluster forest
The cluster forest of $G$ is a forest $\mathcal C$ of rooted trees where each node $u$ corresponds to a cluster $C(u)$.
A node $u$ at level $i\lt l_\max$ has as children the level $(i+1)$-nodes $v$ such that $C(v)\subseteq C(u)$.
Roots of $\mathcal C$ corresponds to connected components of $G$ and leaves of $\mathcal C$ corresponds to vertices of $G$.
Each node $u$ of $\mathcal C$ is associated with its size $n(u)$ which is the number of leaves in the subtree of $\mathcal C$ rooted at $u$.
![[]]
### Answering queries
To determine if vertices $u$ and $v$ are connected in $G$, traverse the leaf-to-root paths from $u$ and $v$ in $\mathcal C$.
Then $u$ and $v$ are connected in $G$ iff the roots are the same. The query time is $O(\log(n))$.
![[]]
### Insert operation
Initialize $l(u,v)$ as $0$.
$r_u,r_v$ are the roots of trees of $\mathcal C$ containing $u$ and $v$, respectively.
If $r_u=r_v$, then $\mathcal C$ is not changed
Otherwise, $r_u$ and $r_v$ are merged.
This corresponds to merging $C(r_u)$ and $C(r_v)$
![[]]
### Delete operation
Let $i=l(u,v)$ and let $C_u$ and $C_v$ be the $(i+1)$-clusters containing $u$ and $v$.
Assume $C_u\ne C_v$ since otherwise, $\mathcal C$ is not changed.
Let $M_i$ be the multigraph with $(i+1)$-clusters as vertices and level $i$-edges of $G$ as edges.
In $M_i$, execute two standard search procedures in parallel, one starting in $C_u$, the other starting in $C_v$.
Terminate both procedures when in one of the following two cases:
- a vertex of $M_i$ is explored by both search procedures
- one of the search procedures has no more edges to explore

![[]]
### Updates to $\mathcal C$
If the two search procedures meet, the level $i$-cluster $C$ containing $(u,v)$ is still connected so $C$ remains a level $i$-cluster.
![[]]
Otherwise, $C$ is to be split in two, one part containing $C_u$ and one containing $C_v$.
![[]]
If $i\gt0$, recurse on level $i-1$.
### Edge level increases after search
Recall: each node $w$ of $\mathcal C$ is associated with its size $n(w)$, which is the number of vertices of $V$ in cluster $C(w)$.
For the search procedure that explored clusters of smallest total size, all its visited edges have their levels increased.
![[]]
### Maintaining the invariant
Parent level $i$-cluster $C$ has size at most $\left\lfloor\dfrac n{2^i}\right\rfloor$
![[]]
The smaller side has size at most $\left\lfloor\dfrac n{2^{i+1}}\right\rfloor$ since otherwise, $C$ would have size:
$$\ge2\left\lceil\dfrac n{2^{i+1}}\right\rceil\gt2\cdot\dfrac n{2^{i+1}}\ge\left\lfloor\dfrac n{2^i}\right\rfloor$$
Thus, the invariant is still satisfied after merging level $(i+1)$-clusters.
### Overall Amortized Analysis
Suppose that each search procedure uses $O(1)$ time per edge visited. For the analysis, we let each edge pay $O(1)$ credits when its level is increased.
The search on the smaller side is thus paid for by its visited edges.
The other search visits the same number of edges $\pm1$.
Hence, the edge level increases can pay for both search procedures.
The max level of an edge is $l_\max=\lfloor\log(n)\rfloor=O(\log(n))$.
Amortized time per update is thus $O(\log(n))$.
The problem with this analysis is that the multigraph $M_i$ is not stored explicitly. Thus, we cannot ensure $O(1)$ time per edge visited. We will instead show how to get $O(\log(n))$ time per edge visited. This will give $O(\log^2(n))$ amortized update time.
### Traversing a single graph edge
![[]]
Assuming a binary cluster forest $\mathcal C$, i.e., every node has at most two children. At each such node $u$, store $l_\max$-bit word, $\text{edge}(u)$. The $i$-th bit $\text{edge}(u)[i]$ is $1$ if and only if a level $i$-edge of $E$ is incident to a leaf of the subtree of $\mathcal C$ rooted at $u$.
```ad-Esempio

```
Maintaining these bitmaps can be done efficiently. Since $\mathcal C$ is binary, we can traverse a single edge of a multigraph in $O(\log(n))$ time using the $\text{edge}$-bit maps.
This gives the desired time bound for the search procedures. However, we need to deal with the cases where $\mathcal C$ is not binary.
### Node ranks and rank trees
Recall: for each node $u$ in $\mathcal C$, $n(u)$ is the number of leaves in the subtree of $\mathcal C$ rooted at $u$.
Define the rank of $u$ as $\text{rank}(u)=\lfloor\log_2(n(u))\rfloor$
Let $u$ be a non-leaf node in $\mathcal C$. Initialize node set $R$ as the children of $u$ in $\mathcal C$.
Rank trees of $u$ are formed by repeating the following procedure as long as two nodes of $R$ have the same rank:
- remove from $R$ two nodes $r_1$ and $r_2$ with $\text{rank}(r_1)=\text{rank}(r_2)$.
- attach $r_1$ and $r_2$ to a parent $r$ of rank $\text{rank}(r)=\text{rank}(r_1)+1$
- add $r$ to $R$

![[]]
### Local trees
Let $r_1,r_2,\ldots,r_k$ be the final set of rank roots in $R$ ordered by decreasing rank:
$$\text{rank}(r_1)\gt\text{rank}(r_2)\gt\ldots\gt\text{rank}(r_k)$$
Local tree $L(u)$ for $k=5$:
![[]]
Replace edges from $u$ to its children in $\mathcal C$ by $L(u)$. Doing this for all $u$ turns $\mathcal C$ into forest $\mathcal C_L$ of binary trees.
$\mathcal C_L$ has height $O(\log(n))$. Merging nodes $u$ and $v$ in $\mathcal C$ involves merging $L(u)$ and $L(v)$ in $\mathcal C_L$.
Splitting a node $u$ involves splitting $L(u)$. This can be done in $O(\log(n))$ time per merge/split and will not increase the asymptotic update time.
### Performance
Each edge pays $O(\log(n))$ credits each time its level increases. Its level can never decrease.
- Number of levels $O(\log(n))$.
- Amortized time per update: $O(\log^2(n))$
- Query time: $O(\log(n))$
- Space: $O(m+n\log(n))$ words

It can be improved by compressing paths in $\mathcal C_L$, whose interior nodes have degree $2$, to single edges. Using a more complicated data structure, both update and query time can be improved by a factor of $\log(\log(n))$. This is still the fastest deterministic data structure known. 
- - -